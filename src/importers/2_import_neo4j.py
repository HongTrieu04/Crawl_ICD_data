import json
from neo4j import GraphDatabase

# ================= C·∫§U H√åNH =================
URI = "neo4j://127.0.0.1:7687" 
AUTH = ("neo4j", "neo4j123") 
DRUG_FILE = "../../data/drug_data_grouped_translated.json"
SYMPTOM_FILE = "../../data/symptoms_extracted_data_translated.json"

class DetailImporter:
    def __init__(self, uri, auth):
        self.driver = GraphDatabase.driver(uri, auth=auth)

    def close(self):
        self.driver.close()

    def create_constraints(self):
        """T·∫°o r√†ng bu·ªôc duy nh·∫•t cho ID c·ªßa Thu·ªëc v√† Tri·ªáu ch·ª©ng"""
        queries = [
            "CREATE CONSTRAINT IF NOT EXISTS FOR (d:Drug) REQUIRE d.ID IS UNIQUE",
            "CREATE CONSTRAINT IF NOT EXISTS FOR (s:Symptom) REQUIRE s.ID IS UNIQUE"
        ]
        with self.driver.session() as session:
            for q in queries:
                session.run(q)
            print("‚úÖ ƒê√£ t·∫°o Constraints cho Drug v√† Symptom.")

    def import_drugs(self, file_path):
        print(f"üíä ƒêang ƒë·ªçc file thu·ªëc: {file_path}...")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except FileNotFoundError:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}")
            return

        query = """
        UNWIND $batch AS item
        // 1. T·∫°o Node Thu·ªëc
        MERGE (d:Drug {ID: item.id})
        SET d.code = item.code,
            d.name = item.name,
            d.scientific_name = item.scientific_name,
            d.description = item.description,
            d.name_vector = [],
            d.desc_vector = []
        
        // 2. T·∫°o quan h·ªá v·ªõi B·ªánh (Lookup c√°c b·ªánh trong danh s√°ch)
        WITH d, item
        UNWIND item.diseases AS disease_code
        // MATCH ƒë·ªÉ ch·ªâ n·ªëi v·ªõi c√°c b·ªánh ƒê√É C√ì trong DB
        MATCH (dis:Disease {ID: disease_code})
        MERGE (d)-[:TREATS]->(dis)
        """

        # Batching: X·ª≠ l√Ω t·ª´ng nh√≥m 1000 item ƒë·ªÉ kh√¥ng qu√° t·∫£i
        batch_size = 1000
        with self.driver.session() as session:
            total = len(data)
            for i in range(0, total, batch_size):
                batch = []
                for item in data[i:i+batch_size]:
                    # Map c√°c tr∆∞·ªùng JSON sang c·∫•u tr√∫c Python dict chu·∫©n
                    batch.append({
                        "id": item.get("id"),
                        "code": item.get("m√£ thu·ªëc", ""),
                        "name": item.get("t√™n thu·ªëc", ""),
                        "scientific_name": item.get("t√™n y sinh", ""),
                        "description": item.get("m√¥ t·∫£", ""),
                        "diseases": item.get("danh s√°ch b·ªánh", [])
                    })
                
                print(f"   ‚Ü≥ ƒêang import batch thu·ªëc {i} - {min(i+batch_size, total)}...")
                session.run(query, batch=batch)
        print("‚úÖ Ho√†n t·∫•t import Thu·ªëc!")

    def import_symptoms(self, file_path):
        print(f"üå°Ô∏è ƒêang ƒë·ªçc file tri·ªáu ch·ª©ng: {file_path}...")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except FileNotFoundError:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {file_path}")
            return

        query = """
        UNWIND $batch AS item
        // 1. T·∫°o Node Tri·ªáu ch·ª©ng
        MERGE (s:Symptom {ID: item.id})
        SET s.code = "",          // D·ªØ li·ªáu tr·ªëng theo y√™u c·∫ßu
            s.name = item.name,
            s.description = "",   // D·ªØ li·ªáu tr·ªëng theo y√™u c·∫ßu
            s.name_vector = [],
            s.desc_vector = []
        
        // 2. T·∫°o quan h·ªá B·ªánh -> C√≥ Tri·ªáu ch·ª©ng
        WITH s, item
        UNWIND item.diseases AS disease_code
        MATCH (dis:Disease {ID: disease_code})
        MERGE (dis)-[:HAS_SYMPTOM]->(s)
        """

        batch_size = 1000
        with self.driver.session() as session:
            total = len(data)
            for i in range(0, total, batch_size):
                batch = []
                for item in data[i:i+batch_size]:
                    batch.append({
                        "id": item.get("id"),
                        "name": item.get("t√™n", ""),
                        "diseases": item.get("b·ªánh", [])
                    })
                
                print(f"   ‚Ü≥ ƒêang import batch tri·ªáu ch·ª©ng {i} - {min(i+batch_size, total)}...")
                session.run(query, batch=batch)
        print("‚úÖ Ho√†n t·∫•t import Tri·ªáu ch·ª©ng!")

if __name__ == "__main__":
    importer = DetailImporter(URI, AUTH)
    try:
        importer.create_constraints()
        # Ch·∫°y l·∫ßn l∆∞·ª£t
        importer.import_drugs(DRUG_FILE)
        print("-" * 30)
        importer.import_symptoms(SYMPTOM_FILE)
    finally:
        importer.close()