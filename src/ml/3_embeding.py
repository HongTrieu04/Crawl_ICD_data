import json
import torch
import os
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm # Th∆∞ vi·ªán t·∫°o thanh ti·∫øn ƒë·ªô (pip install tqdm)

# ================= C·∫§U H√åNH =================
MODEL_PATH = "../../models/vietnamese-embedding" # ƒê∆∞·ªùng d·∫´n model local
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 32

# File ƒë·∫ßu v√†o
INPUT_FILES = {
    "icd10": "../../data/icd10_data.json",
    "drugs": "../../data/drug_data_grouped_translated.json",
    "symptoms": "../../data/symptoms_extracted_data_translated.json"
}

# File ƒë·∫ßu ra
OUTPUT_FILES = {
    "icd10": "../../data/icd10_embedded.json",
    "drugs": "../../data/drugs_embedded.json",
    "symptoms": "../../data/symptoms_embedded.json"
}

class EmbeddingGenerator:
    def __init__(self, model_path):
        print(f"‚öôÔ∏è ƒêang t·∫£i model tr√™n thi·∫øt b·ªã: {DEVICE}...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModel.from_pretrained(model_path, trust_remote_code=True, torch_dtype=torch.float16 if DEVICE=="cuda" else torch.float32)
        self.model.to(DEVICE)
        self.model.eval()

    def get_embedding(self, text):
        """H√†m t√≠nh vector cho 1 c√¢u text ƒë∆°n l·∫ª"""
        if not text or not isinstance(text, str) or text.strip() == "":
            return [] # Tr·∫£ v·ªÅ m·∫£ng r·ªóng n·∫øu kh√¥ng c√≥ text
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i text tr∆∞·ªõc khi tokenize (ƒë·ªÉ tr√°nh l·ªói position embedding)
        text = text.strip()[:5000]  # Gi·ªõi h·∫°n k√Ω t·ª± tr∆∞·ªõc khi tokenize
        
        with torch.no_grad():
            inputs = self.tokenizer(
                text, 
                return_tensors="pt", 
                padding=True, 
                truncation=True, 
                max_length=256  # Gi·∫£m xu·ªëng 256 thay v√¨ 512 ƒë·ªÉ an to√†n h∆°n
            )
            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
            
            # Th√™m ki·ªÉm tra ƒë·ªÉ ƒë·∫£m b·∫£o input_ids kh√¥ng v∆∞·ª£t qu√° gi·ªõi h·∫°n
            if inputs['input_ids'].shape[1] > 512:
                print(f"‚ö†Ô∏è C·∫£nh b√°o: Text qu√° d√†i ({inputs['input_ids'].shape[1]} tokens), ƒëang c·∫Øt b·ªõt...")
                inputs['input_ids'] = inputs['input_ids'][:, :512]
                inputs['attention_mask'] = inputs['attention_mask'][:, :512]
            
            outputs = self.model(**inputs)
            
            # Mean Pooling
            last_hidden_states = outputs.last_hidden_state
            attention_mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden_states.size()).float()
            sum_embeddings = torch.sum(last_hidden_states * attention_mask, 1)
            sum_mask = torch.clamp(attention_mask.sum(1), min=1e-9)
            mean_embeddings = sum_embeddings / sum_mask
            
            return mean_embeddings.cpu().numpy()[0].tolist()

    def process_icd10_recursive(self, items):
        """Duy·ªát ƒë·ªá quy c·∫•u tr√∫c c√¢y ICD-10 ƒë·ªÉ th√™m vector"""
        for item in tqdm(items, desc="X·ª≠ l√Ω node ICD-10", leave=False):
            # X·ª≠ l√Ω vector d·ª±a tr√™n type
            item['name_vector'] = self.get_embedding(item.get('name', ''))
            item['desc_vector'] = self.get_embedding(item.get('description', ''))
            
            # Ri√™ng Group c√≥ th√™m code_vector
            if item.get('type') == 'group':
                item['code_vector'] = self.get_embedding(item.get('code', '')) # D√πng code l√†m ID vector
            
            # ƒê·ªá quy xu·ªëng con (children)
            if 'children' in item and isinstance(item['children'], list):
                self.process_icd10_recursive(item['children'])
        return items

    def process_flat_list(self, items, type_label):
        """X·ª≠ l√Ω danh s√°ch ph·∫≥ng (Thu·ªëc, Tri·ªáu ch·ª©ng)"""
        for item in tqdm(items, desc=f"X·ª≠ l√Ω {type_label}"):
            # Mapping d·ªØ li·ªáu d·ª±a tr√™n lo·∫°i file
            if type_label == "Drug":
                # Thu·ªëc
                item['name_vector'] = self.get_embedding(item.get('t√™n thu·ªëc', ''))
                item['desc_vector'] = self.get_embedding(item.get('m√¥ t·∫£', ''))
            elif type_label == "Symptom":
                # Tri·ªáu ch·ª©ng
                item['name_vector'] = self.get_embedding(item.get('t√™n', ''))
                item['desc_vector'] = self.get_embedding(item.get('m√¥ t·∫£', '')) # N·∫øu file g·ªëc kh√¥ng c√≥ th√¨ tr·∫£ v·ªÅ []
                # Tri·ªáu ch·ª©ng code ch∆∞a c√≥ n√™n b·ªè qua code_vector
            
        return items

    def run(self):
        # 1. X·ª≠ l√Ω ICD-10 (C·∫•u tr√∫c ph√¢n c·∫•p)
        if os.path.exists(INPUT_FILES['icd10']):
            print("\nüì• ƒêang x·ª≠ l√Ω file ICD-10...")
            with open(INPUT_FILES['icd10'], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # G·ªçi h√†m ƒë·ªá quy
            processed_data = self.process_icd10_recursive(data)
            
            with open(OUTPUT_FILES['icd10'], 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ ƒê√£ xu·∫•t file: {OUTPUT_FILES['icd10']}")

        # 2. X·ª≠ l√Ω Thu·ªëc (Danh s√°ch ph·∫≥ng)
        if os.path.exists(INPUT_FILES['drugs']):
            print("\nüì• ƒêang x·ª≠ l√Ω file Thu·ªëc...")
            with open(INPUT_FILES['drugs'], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            processed_data = self.process_flat_list(data, "Drug")
            
            with open(OUTPUT_FILES['drugs'], 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ ƒê√£ xu·∫•t file: {OUTPUT_FILES['drugs']}")

        # 3. X·ª≠ l√Ω Tri·ªáu ch·ª©ng (Danh s√°ch ph·∫≥ng)
        if os.path.exists(INPUT_FILES['symptoms']):
            print("\nüì• ƒêang x·ª≠ l√Ω file Tri·ªáu ch·ª©ng...")
            with open(INPUT_FILES['symptoms'], 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            processed_data = self.process_flat_list(data, "Symptom")
            
            with open(OUTPUT_FILES['symptoms'], 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ ƒê√£ xu·∫•t file: {OUTPUT_FILES['symptoms']}")

if __name__ == "__main__":
    generator = EmbeddingGenerator(MODEL_PATH)
    generator.run()